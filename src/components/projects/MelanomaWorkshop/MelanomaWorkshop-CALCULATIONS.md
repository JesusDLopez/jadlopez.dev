# Melanoma Workshop Evaluation ‚Äî Calculation Verification Document

**Purpose:** Ensure scientific accuracy of the R ‚Üí JSON ‚Üí Web visualization pipeline

**Created:** 2025-10-10
**Status:** Template ready for data verification
**Reference:** See `MelanomaWorkshop-DEVELOPMENT_LOG.md` for project context

---

## üìã Table of Contents

0. [**DATA FILE AUDIT - READ THIS FIRST**](#data-file-audit)
1. [Survey Question Inventory](#survey-question-inventory)
2. [Data Transformations Log](#data-transformations-log)
3. [Descriptive Statistics Verification](#descriptive-statistics-verification)
4. [Paired T-Test Results](#paired-t-test-results)
5. [Aggregated Metrics](#aggregated-metrics)
6. [R to JSON Export Scripts](#r-to-json-export-scripts)
7. [Final Verification Checklist](#final-verification-checklist)

---

## üîç DATA FILE AUDIT

**‚ö†Ô∏è CRITICAL: Read this section BEFORE any analysis to ensure correct data files are used**

**üö® MAJOR DISCOVERY: This project involves TWO SEPARATE WORKSHOPS, not one!**

### Data File Structure Overview

The Melanoma Workshop data exists in multiple files with different purposes. **CRITICALLY, there were TWO workshops conducted**, and different data files contain different combinations of workshop data.

---

### üéØ TWO WORKSHOPS IDENTIFIED

**Verified 2025-10-10:**

| Workshop | Participant IDs | Pre N | Post N | Location/Date |
|----------|-----------------|-------|--------|---------------|
| **Workshop 1 (Original)** | 0015-0099 | ~42 | ~39 | Unknown (earlier) |
| **Workshop 2 (Perth)** | 0102-0113 | 8 | 9 | Perth, July 2024 |
| **COMBINED** | 0015-0113 | 53 | 54 | Both workshops |

**Key Evidence:**
- **Workshop 1:** Lower ID numbers (0015, 0019, 0020... 0093, 0094, 0098, 0099)
- **Workshop 2 (Perth):** Higher ID numbers (0102, 0103, 0104, 0105, 0106, 0108, 0109, 0111, 0113)
- **Folder name:** "AfterPerthWKS" = data compiled AFTER the Perth workshop
- **File dates:** Raw_Data files (Oct 2023), AfterPerthWKS files (Jul 2024)

---

### üìä Which Files Contain Which Workshops?

**Critical Understanding:**

| File Location | Contains | Pre N | Post N | IDs Range |
|---------------|----------|-------|--------|-----------|
| **`/Raw_Data/`** | **Workshop 1 ONLY** | 38 | 39 | 0015-0099 |
| **`/Processed_Data/`** | **Workshop 1 ONLY (paired)** | 35 | 35 | 0019-0098 |
| **`/AfterPerthWKS/`** | **BOTH Workshops 1 & 2** | 53 | 54 | 0015-0113 |

---

### üìÇ File Details by Location

#### üìÅ Raw_Data Files (Workshop 1 Only)

**Location:** `/Raw_Data/`
**Contains:** ONLY Workshop 1 participants (IDs 0015-0099)
**Created:** October 2023 (before Perth workshop)

| File | Participants | Description | Use For |
|------|--------------|-------------|---------|
| **Pre-WKS-Raw.csv** | 38 | Workshop 1 pre-workshop responses | Reference only |
| **Post-WKS-Raw.csv** | 39 | Workshop 1 post-workshop responses | Reference only |
| **Pre-WKS-Clean.csv** | 38 | Cleaned Workshop 1 pre (scale corrected) | Workshop 1 analysis only |
| **Post-WKS-Clean.csv** | 39 | Cleaned Workshop 1 post | Workshop 1 analysis only |

**‚ö†Ô∏è WARNING:** These files do NOT include Perth workshop participants (IDs 0102-0113)!

---

#### üìÅ Processed_Data Files (Workshop 1 Only, Paired)

**Location:** `/Processed_Data/`
**Contains:** ONLY Workshop 1 participants who completed BOTH surveys (IDs 0019-0098)
**Created:** From Raw_Data files (Workshop 1 only)

| File | Participants | Description | **Use For** |
|------|--------------|-------------|-------------|
| **Paired-Pre-WKS-Clean.csv** | **35** | Workshop 1 pre (paired only) | ‚úÖ Workshop 1 paired t-tests (PRE) |
| **Paired-Post-WKS-Clean.csv** | **35** | Workshop 1 post (paired only) | ‚úÖ Workshop 1 paired t-tests (POST) |
| **Common-Pre-WKS-Clean.csv** | 35 | Same as Paired-Pre | Identical to Paired-Pre |
| **Common-Post-WKS-Clean.csv** | 35 | Same as Paired-Post | Identical to Paired-Post |

**‚úì KEY FINDING:** Common and Paired files are **IDENTICAL** (same 35 participants). Either can be used.

**‚ö†Ô∏è CRITICAL LIMITATION:** These files **EXCLUDE the Perth workshop** (IDs 0102-0113) entirely!

---

#### üìÅ AfterPerthWKS Files (BOTH Workshops Combined)

**Location:** `/AfterPerthWKS/`
**Contains:** BOTH Workshop 1 (0015-0099) AND Perth Workshop 2 (0102-0113)
**Created:** July 2024 (after Perth workshop)

| File | Total N | Workshop 1 | Perth (Wksp 2) | Description |
|------|---------|------------|----------------|-------------|
| **Pre_WKS_Responses.csv** | 53 | ~42 | ~8 | Combined pre-workshop (both) |
| **Post_WKS_Responses.csv** | 54 | ~39 | ~9 | Combined post-workshop (both) |
| **Survey Responses 9 Jul 2024.xlsx** | 53/54 | Both workshops | Master Excel file |

**Perth Workshop Participants (IDs):**
- **Pre:** 0102, 0103, 0104, 0105, 0106, 0108, 0109, 0111 (8 participants)
- **Post:** 0102, 0103, 0104, 0105, 0106, 0108, 0109, 0111, 0113 (9 participants)

**‚ö†Ô∏è Data Quality Note:** Participant 0111 appears twice in Pre file (potential duplicate)

---

### üìë Master Data File (Excel)

**File:** `AfterPerthWKS/Survey Responses 9 Jul 2024.xlsx`

**Structure:**
- **Sheet 1: "PRE"** - Contains 38 pre-workshop responses (includes 3 unpaired)
- **Sheet 2: "POST"** - Contains 39 post-workshop responses (includes 4 unpaired)

**Used By:** R script `Cleaning.rmd` reads this Excel file and generates all CSV files.

**R Code Reference (Cleaning.rmd lines 31-36):**
```r
file_path <- ".../Survey Responses 9 Jul 2024.xlsx"
pre_wks_data <- read_excel(file_path, sheet = "PRE", skip = 2)
post_wks_data <- read_excel(file_path, sheet = "POST", skip = 2)
```

---

### üî¢ Complete Participant Breakdown

**Verified 2025-10-10:**

```
WORKSHOP 1 (Original, IDs 0015-0099):
                        PRE    POST   PAIRED
Raw_Data:                38     39     35
Processed_Data:          35     35     35

WORKSHOP 2 (Perth, IDs 0102-0113):
                        PRE    POST   PAIRED
AfterPerthWKS:           8      9      7-8 (approx)

COMBINED (BOTH WORKSHOPS):
                        PRE    POST   TOTAL
AfterPerthWKS:          53     54     ~107
```

#### Workshop 1 Unpaired Participants:

**Pre-Only (3 participants):** 0020, 0056, 0099
**Post-Only (4 participants):** 0004, 0030, 0065, 0066

#### Perth Workshop (Workshop 2) Participants:

**Pre (8):** 0102, 0103, 0104, 0105, 0106, 0108, 0109, 0111 (note: 0111 appears twice - duplicate?)
**Post (9):** 0102, 0103, 0104, 0105, 0106, 0108, 0109, 0111, 0113
**Paired:** ~7-8 participants (0102-0109, 0111 common to both)

---

### üö® CRITICAL DECISION REQUIRED

**Which analysis approach should be used?**

#### Option 1: Workshop 1 Only (N=35 paired)
**Files:** `/Processed_Data/Paired-*.csv`
**Pros:**
- ‚úÖ Already cleaned and processed
- ‚úÖ Larger sample size (35 vs ~7)
- ‚úÖ Higher statistical power
- ‚úÖ Existing analyses use this

**Cons:**
- ‚ùå Excludes Perth workshop data
- ‚ùå Not representative of both workshops
- ‚ùå Wastes data from 8-9 Perth participants

**Response Rate:** 92.1% (35/38 pre)

---

#### Option 2: BOTH Workshops Combined (N=~42 paired)
**Files:** `/AfterPerthWKS/Pre_WKS_Responses.csv`, `Post_WKS_Responses.csv`
**Pros:**
- ‚úÖ Uses ALL available data
- ‚úÖ Representative of both workshop contexts
- ‚úÖ Larger combined sample (N‚âà42-45 paired)
- ‚úÖ More generalizable findings

**Cons:**
- ‚ùå Requires re-processing AfterPerthWKS files
- ‚ùå Potential heterogeneity (two different workshops)
- ‚ùå Data quality issues (duplicate 0111)
- ‚ùå May need to account for workshop as variable

**Response Rate:** ~79% combined ([35+7]/[53])

---

#### Option 3: Separate Analyses
**Files:** Workshop 1 from `/Processed_Data/`, Workshop 2 from `/AfterPerthWKS/` (manual extraction)
**Pros:**
- ‚úÖ Can compare effectiveness between workshops
- ‚úÖ Accounts for context differences
- ‚úÖ Most scientifically rigorous

**Cons:**
- ‚ùå Perth sample too small (N‚âà7) for reliable statistics
- ‚ùå More complex analysis and reporting
- ‚ùå Requires extracting Perth data separately

---

### ‚úÖ DECISION RESOLVED (2025-10-10)

**Selected Approach:** **Option 2 - BOTH Workshops Combined**

**Rationale:**
- Maximizes sample size (N=48 paired vs N=35)
- Most representative of workshop effectiveness across contexts
- Uses ALL available data appropriately
- Higher statistical power for detecting effects

---

### ‚úÖ CORRECT FILES & SAMPLE SIZES FOR ANALYSIS

**Master Data File (USE THIS):**

```r
# Load the master Excel file with BOTH workshops
library(readxl)

file_path <- "/Users/.../AfterPerthWKS/Survey Responses 9 Jul 2024.xlsx"

# Read both sheets
pre_wks_data <- read_excel(file_path, sheet = "PRE", skip = 2)   # N=51
post_wks_data <- read_excel(file_path, sheet = "POST", skip = 2) # N=53

# Apply data cleaning (scale transformations, missing values, etc.)
# ... (see Data Transformations Log section)

# After cleaning, identify paired participants
paired_ids <- intersect(pre_wks_data$`Participant ID`,
                        post_wks_data$`Participant ID`)
# N=48 paired participants
```

**Sample Sizes:**
- **Pre-workshop (ALL):** N = 51 participants
- **Post-workshop (ALL):** N = 53 participants
- **Paired (BOTH surveys):** N = 48 participants
- **Total unique participants:** 56
- **Response rate:** 85.7% (48/56)

---

### üìä Data Usage Strategy: When to Use ALL vs PAIRED

**CRITICAL: Different analyses require different sample sizes!**

#### ‚úÖ Use ALL Participants (N=51 pre / N=53 post)

**For Descriptive Statistics:**
- Pre-workshop baseline attitudes (N=51)
- Post-workshop outcomes (N=53)
- Frequency distributions
- Means, SDs, medians
- Demographic characteristics

**Why:** Provides most complete picture, maximum statistical power for descriptive stats

**Example:**
```r
# Descriptive stats for Q1.1 at baseline
describe(pre_wks_data$`1.1`)  # Uses all 51 pre-workshop participants
```

---

#### ‚úÖ Use PAIRED Participants Only (N=48)

**For Pre/Post Comparisons:**
- Paired t-tests
- Knowledge change analysis
- Effect sizes (Cohen's d)
- Workshop effectiveness evaluation
- Any statistical test comparing before/after

**Why:** Paired tests REQUIRE same participants in both groups

**Example:**
```r
# First, filter to paired participants only
paired_pre <- pre_wks_data %>% filter(`Participant ID` %in% paired_ids)   # N=48
paired_post <- post_wks_data %>% filter(`Participant ID` %in% paired_ids) # N=48

# Now run paired t-test
t.test(paired_post$`1.1`, paired_pre$`1.1`, paired = TRUE)
```

---

### ‚ùå OUTDATED FILES (DO NOT USE - Pre-Perth Workshop Only)

**‚ö†Ô∏è WARNING: These files are INCOMPLETE - they only contain Workshop 1 (N=35) and exclude Perth workshop participants!**

**Processed_Data Files (N=35 - OUTDATED):**
```r
# ‚ùå OUTDATED - Only contains Workshop 1, created before Perth workshop
pre_data <- read.csv("Processed_Data/Paired-Pre-WKS-Clean.csv")    # N=35 (missing 13 paired!)
post_data <- read.csv("Processed_Data/Paired-Post-WKS-Clean.csv")  # N=35 (missing 13 paired!)
```

**Raw_Data Files (N=38/39 - OUTDATED):**
```r
# ‚ùå OUTDATED - Only contains Workshop 1
pre_data <- read.csv("Raw_Data/Pre-WKS-Clean.csv")    # N=38 (Workshop 1 only)
post_data <- read.csv("Raw_Data/Post-WKS-Clean.csv")  # N=39 (Workshop 1 only)
```

**Why these are wrong:**
- Created October 2023 (before Perth workshop in July 2024)
- Missing 8-9 Perth workshop participants
- Only gives you N=35 paired instead of N=48
- Reduces statistical power
- Not representative of full workshop series

**If you use these files, you'll be missing ~27% of your data!**

---

### üß™ Verification Test

**Run this in R to verify you're using the CORRECT master file:**

```r
library(readxl)

# Load the CORRECT master file
file_path <- "/Users/.../AfterPerthWKS/Survey Responses 9 Jul 2024.xlsx"
pre_data <- read_excel(file_path, sheet = "PRE", skip = 2)
post_data <- read_excel(file_path, sheet = "POST", skip = 2)

# Check 1: Sample size (should be larger than old files!)
cat("Pre N:", nrow(pre_data), "\n")    # Should be: 51 (not 38!)
cat("Post N:", nrow(post_data), "\n")  # Should be: 53 (not 39!)

# Check 2: Contains Perth workshop participants (IDs 0102-0113)
perth_ids <- c("0102", "0103", "0104", "0105", "0106", "0108", "0109", "0111", "0113")
pre_has_perth <- any(perth_ids %in% pre_data$`Participant ID`)
post_has_perth <- any(perth_ids %in% post_data$`Participant ID`)
cat("Pre contains Perth participants:", pre_has_perth, "\n")   # Should be: TRUE
cat("Post contains Perth participants:", post_has_perth, "\n") # Should be: TRUE

# Check 3: Paired participant count
paired_ids <- intersect(pre_data$`Participant ID`, post_data$`Participant ID`)
cat("Paired participants:", length(paired_ids), "\n")  # Should be: 48

# Check 4: File date verification
cat("Using master file from AfterPerthWKS folder: ",
    grepl("AfterPerthWKS", file_path), "\n")  # Should be: TRUE
cat("Paired t-test works:", !is.null(test), "\n")  # Should be: TRUE
```

**Expected Output:**
```
Pre N: 51
Post N: 53
Pre contains Perth participants: TRUE
Post contains Perth participants: TRUE
Paired participants: 48
Using master file from AfterPerthWKS folder: TRUE
```

**If any check fails, STOP and investigate before proceeding.**

---

### üìù Summary for JSON Export

**Use these CORRECT values (updated 2025-10-10):**

```json
{
  "demographics": {
    "totalPreWorkshop": 51,
    "totalPostWorkshop": 53,
    "pairedParticipants": 48,
    "totalUniqueParticipants": 56,
    "responseRate": 85.7,
    "workshops": {
      "workshop1": {
        "location": "Original location",
        "date": "2023",
        "participantIDRange": "0015-0099",
        "pairedParticipants": 35
      },
      "workshop2Perth": {
        "location": "Perth, Australia",
        "date": "July 2024",
        "participantIDRange": "0102-0113",
        "pairedParticipants": 8
      }
    },
    "dataUsage": {
      "descriptiveStats": "Use ALL participants (N=51 pre, N=53 post)",
      "pairedComparisons": "Use PAIRED only (N=48)"
    }
  }
}
```

---

## üìù Survey Question Inventory

### Question 1.1
**Full Text:** "Melanoma genomic testing is relevant to my practice today"
**Scale:** 1 (Strongly Disagree) ‚Üí 2 ‚Üí 3 ‚Üí 4 ‚Üí 5 (Strongly Agree)
**‚ö†Ô∏è Transformation:** REVERSED in original survey (Strongly Agree = 1, Strongly Disagree = 5)
**Correction Applied:** 1‚Üî5, 2‚Üî4, 3 unchanged
**R Variable (Pre):** `pre_wks_data$'1.1'`
**R Variable (Post):** `post_wks_data$'1.1'`
**Category:** Attitudes - Current Relevance

---

### Question 1.2
**Full Text:** "Melanoma genomic testing will become increasingly relevant in the future"
**Scale:** 1 (Strongly Disagree) ‚Üí 2 ‚Üí 3 ‚Üí 4 ‚Üí 5 (Strongly Agree)
**‚ö†Ô∏è Transformation:** REVERSED in original survey
**Correction Applied:** 1‚Üî5, 2‚Üî4, 3 unchanged
**R Variable (Pre):** `pre_wks_data$'1.2'`
**R Variable (Post):** `post_wks_data$'1.2'`
**Category:** Attitudes - Future Relevance

---

### Question 2
**Full Text:** [To be filled from survey instrument]
**Scale:** 1 (Strongly Disagree) ‚Üí 5 (Strongly Agree)
**Transformation:** None (already correct orientation)
**R Variable (Pre):** `pre_wks_data$'2'`
**R Variable (Post):** `post_wks_data$'2'`
**Category:** [Knowledge/Attitudes]

---

### Question 3 (Pre-Workshop Only)
**Full Text:** [To be filled from Q3-Pre analysis]
**Scale:** [To be documented]
**Transformation:** None
**R Variable (Pre):** `pre_wks_data$'3'`
**R Variable (Post):** N/A (Pre-workshop only)
**Category:** [To be classified]

---

### Question 4 (Post-Workshop Analysis)
**Full Text:** [To be filled from Q4-Post analysis]
**Scale:** 1 (Strongly Disagree) ‚Üí 5 (Strongly Agree)
**Transformation:** None
**R Variable (Pre):** N/A
**R Variable (Post):** `post_wks_data$'4'`
**Category:** [Post-workshop evaluation]

---

### Questions 5-9 (Post-Workshop)
**Note:** These appear to be post-workshop specific questions based on file structure.

**Q5:** [To be filled]
**Q6:** [To be filled]
**Q7:** [To be filled]
**Q8:** [To be filled]
**Q9:** [To be filled]

---

### Questions 10-12 (Qualitative/Additional)
**Note:** Based on "Q10, Q11, Q12 + Additional Thoughts.Rmd"

**Q10:** [Open-ended feedback - to be coded]
**Q11:** [Open-ended feedback - to be coded]
**Q12:** [Open-ended feedback - to be coded]

---

## üîÑ Data Transformations Log

### 1. Scale Reversal (Q1.1, Q1.2)

**Issue:** Original survey incorrectly coded Strongly Agree = 1, Strongly Disagree = 5

**R Code Applied (from Cleaning.rmd lines 70-100):**
```r
# Pre-workshop scale adjustment
pre_wks_data <- pre_wks_data %>%
  mutate(`1.1` = case_when(
    `1.1` == 1 ~ 5,
    `1.1` == 2 ~ 4,
    `1.1` == 4 ~ 2,
    `1.1` == 5 ~ 1,
    TRUE ~ `1.1`  # 3 stays as 3
  ),
  `1.2` = case_when(
    `1.2` == 1 ~ 5,
    `1.2` == 2 ~ 4,
    `1.2` == 4 ~ 2,
    `1.2` == 5 ~ 1,
    TRUE ~ `1.2`
  ))

# Post-workshop scale adjustment (identical code)
post_wks_data <- post_wks_data %>%
  mutate(`1.1` = case_when(...))  # Same transformation
```

**Verification Method:**
- Check raw Excel file: Participant who strongly agreed should have "1" in raw data
- After transformation: Should show "5" in cleaned data
- Cross-check: High agreement responses should result in high numeric scores (4-5)

**Questions Affected:** Only Q1.1 and Q1.2
**Status:** ‚úì Applied to both pre and post datasets

---

### 2. Missing Value Conversion

**Issue:** Excel file used "N/A" text for missing responses, R doesn't recognize as missing

**R Code Applied (from Cleaning.rmd lines 42-47):**
```r
# Convert "N/A" string to proper NA values
pre_wks_data <- pre_wks_data %>%
  mutate(across(where(is.character), ~na_if(.x, "N/A")))

post_wks_data <- post_wks_data %>%
  mutate(across(where(is.character), ~na_if(.x, "N/A")))
```

**Missing Data Summary:**
- **Total Pre-Workshop Participants:** [Fill from data: e.g., 30]
- **Total Post-Workshop Participants:** [Fill from data: e.g., 28]
- **Paired Participants (both surveys):** [Fill from data: e.g., 25]
- **Missing Q1.1 (Pre):** [Count]
- **Missing Q1.1 (Post):** [Count]
- **Missing Q1.2 (Pre):** [Count]
- **Missing Q1.2 (Post):** [Count]

---

### 3. Numeric Type Conversion

**Issue:** Excel imports all values as character strings

**R Code Applied (from Cleaning.rmd lines 54-62):**
```r
# Pre-workshop numeric columns
numeric_columns_pre <- c("1.1", "1.2", "101", "102", "103",
                          "104", "105", "106", "107", "108",
                          "109", "110", "111", "112")

pre_wks_data[numeric_columns_pre] <-
  lapply(pre_wks_data[numeric_columns_pre],
         function(x) as.numeric(as.character(x)))

# Post-workshop (includes additional questions 4-9)
numeric_columns_post <- c("1.1", "1.2", "101", "102", "103",
                           "104", "105", "106", "107", "108",
                           "109", "110", "111", "112",
                           "4", "5", "6", "7", "8", "9")

post_wks_data[numeric_columns_post] <-
  lapply(post_wks_data[numeric_columns_post],
         function(x) as.numeric(as.character(x)))
```

**Verification:** After conversion, `class(pre_wks_data$'1.1')` should return "numeric"

---

### 4. Paired Participant Filtering

**Data Files Used:**
- **Common Pre:** All pre-workshop respondents (N = [e.g., 30])
- **Common Post:** All post-workshop respondents (N = [e.g., 28])
- **Paired Pre:** Only participants who completed both surveys (N = [e.g., 25])
- **Paired Post:** Only participants who completed both surveys (N = [e.g., 25])

**Analysis Decision:** Use PAIRED datasets for pre/post comparison to ensure valid matched pairs for t-tests.

**Response Rate Calculation:**
```r
response_rate <- (n_paired / n_pre_total) * 100
# Example: (25 / 30) * 100 = 83.3%
```

---

## üìä Descriptive Statistics Verification

### Template for Each Question

**For each question, complete this verification block:**

---

### Q1.1 ‚Äî Relevance to Practice Today

#### Pre-Workshop Descriptive Statistics

**R Output (from Cleaning.rmd or Q1.Rmd - `describe()` function):**
```r
library(psych)
describe(pre_wks_data$`1.1`)

# Output:
#    vars  n  mean   sd median trimmed  mad min max range  skew kurtosis   se
# 1     1 [N] [M.MM] [S.SS]    [X]   [X.XX] [X.XX]  1   5     4 [X.XX]   [X.XX] [X.XX]
```

**Extracted Values:**
- **N (sample size):** _____ participants
- **Mean:** _____ (range: 1-5)
- **SD (standard deviation):** _____
- **Median:** _____
- **Min:** _____ (should be 1)
- **Max:** _____ (should be 5)

**95% Confidence Interval Calculation:**
```r
# CI formula: mean ¬± 1.96 * (sd / sqrt(n))
mean_q1_1 <- [FILL]
sd_q1_1 <- [FILL]
n_q1_1 <- [FILL]

se_q1_1 <- sd_q1_1 / sqrt(n_q1_1)
ci_lower <- mean_q1_1 - 1.96 * se_q1_1
ci_upper <- mean_q1_1 + 1.96 * se_q1_1

# CI: [ci_lower, ci_upper]
```

**Manual Verification:**
- [ ] Mean is between 1 and 5: _____ ‚úì/‚úó
- [ ] SD is reasonable (typically 0.5 - 1.5 for Likert): _____ ‚úì/‚úó
- [ ] N matches total paired participants: _____ ‚úì/‚úó
- [ ] CI calculated correctly: [_____, _____] ‚úì/‚úó

---

**Frequency Distribution:**

**R Code:**
```r
table(pre_wks_data$`1.1`)
# Outputs count for each response (1-5)
```

**Results:**
| Response | Label              | Count | Percentage |
|----------|--------------------|-------|------------|
| 1        | Strongly Disagree  | ___   | ___%       |
| 2        | Disagree           | ___   | ___%       |
| 3        | Neutral            | ___   | ___%       |
| 4        | Agree              | ___   | ___%       |
| 5        | Strongly Agree     | ___   | ___%       |
| **Total**|                    | **___**| **100%**  |

**Visual Check:** Distribution should sum to N = _____

---

**Expected JSON Format:**
```json
{
  "q1_1": {
    "label": "Melanoma genomic testing is relevant to my practice today",
    "category": "Attitudes - Current Relevance",
    "preWorkshop": {
      "mean": _____,
      "sd": _____,
      "n": _____,
      "median": _____,
      "ci95": [_____, _____],
      "responses": {
        "1": ___,
        "2": ___,
        "3": ___,
        "4": ___,
        "5": ___
      }
    }
  }
}
```

**Verification Checklist:**
- [ ] Mean value matches R output exactly
- [ ] SD matches R output exactly
- [ ] N matches paired participant count
- [ ] CI calculated manually and verified
- [ ] Response frequencies sum to N
- [ ] JSON structure is valid (no syntax errors)

---

#### Post-Workshop Descriptive Statistics

**R Output:**
```r
describe(post_wks_data$`1.1`)

# Output:
#    vars  n  mean   sd median trimmed  mad min max range  skew kurtosis   se
# 1     1 [N] [M.MM] [S.SS]    [X]   [X.XX] [X.XX]  1   5     4 [X.XX]   [X.XX] [X.XX]
```

**Extracted Values:**
- **N:** _____ (should match pre-workshop N for paired analysis)
- **Mean:** _____
- **SD:** _____
- **Median:** _____
- **95% CI:** [_____, _____]

**Frequency Distribution:**
| Response | Count | Percentage |
|----------|-------|------------|
| 1        | ___   | ___%       |
| 2        | ___   | ___%       |
| 3        | ___   | ___%       |
| 4        | ___   | ___%       |
| 5        | ___   | ___%       |
| **Total**| **___**| **100%**  |

**Expected JSON:**
```json
{
  "q1_1": {
    "postWorkshop": {
      "mean": _____,
      "sd": _____,
      "n": _____,
      "median": _____,
      "ci95": [_____, _____],
      "responses": {
        "1": ___,
        "2": ___,
        "3": ___,
        "4": ___,
        "5": ___
      }
    }
  }
}
```

**Verification:**
- [ ] Post N equals Pre N (paired data requirement)
- [ ] Post mean ‚â• Pre mean (if workshop effective)
- [ ] All values extracted correctly
- [ ] JSON valid

---

#### Pre vs Post Comparison (Q1.1)

**Change Metrics:**
```r
# Mean difference
mean_diff <- post_mean - pre_mean
# Example: 4.1 - 3.2 = 0.9

# Percent change
pct_change <- (mean_diff / pre_mean) * 100
# Example: (0.9 / 3.2) * 100 = 28.1%
```

**Calculated Values:**
- **Mean Difference:** _____ (Post - Pre)
- **Percent Change:** _____%
- **Direction:** Increase / Decrease / No Change

**Expected JSON:**
```json
{
  "q1_1": {
    "change": {
      "meanDifference": _____,
      "percentChange": _____,
      "direction": "increase"
    }
  }
}
```

**Visual Comparison:**
| Metric       | Pre-Workshop | Post-Workshop | Change |
|--------------|--------------|---------------|--------|
| Mean         | _____        | _____         | +_____ |
| SD           | _____        | _____         | ¬±_____ |
| Median       | _____        | _____         | +_____ |

---

### Q1.2 ‚Äî Future Relevance

**[Repeat entire structure above for Q1.2]**

#### Pre-Workshop Descriptive Statistics
- **N:** _____
- **Mean:** _____
- **SD:** _____
- **CI 95%:** [_____, _____]

**Frequency Distribution:**
| Response | Count | Percentage |
|----------|-------|------------|
| 1        | ___   | ___%       |
| 2        | ___   | ___%       |
| 3        | ___   | ___%       |
| 4        | ___   | ___%       |
| 5        | ___   | ___%       |

#### Post-Workshop Descriptive Statistics
- **N:** _____
- **Mean:** _____
- **SD:** _____
- **CI 95%:** [_____, _____]

**Frequency Distribution:**
| Response | Count | Percentage |
|----------|-------|------------|
| 1        | ___   | ___%       |
| 2        | ___   | ___%       |
| 3        | ___   | ___%       |
| 4        | ___   | ___%       |
| 5        | ___   | ___%       |

#### Change Summary
- **Mean Difference:** _____
- **Percent Change:** _____%

---

### Questions 2-12

**[For each remaining question, fill in the same template structure]**

**Note:** Questions 4-9 may be post-workshop only. If so, mark Pre-Workshop sections as "N/A" and focus on post-workshop descriptive stats only.

---

## üìà Paired T-Test Results

### Statistical Test Template (for each paired question)

---

### Q1.1 ‚Äî Paired T-Test

**Research Hypothesis:** Workshop increases perceived current relevance of genomic testing

**R Code (from Q1.Rmd or Q4-Post-Q3-Pre.Rmd):**
```r
# Paired t-test (two-tailed)
t_test_q1_1 <- t.test(
  post_wks_data$`1.1`,
  pre_wks_data$`1.1`,
  paired = TRUE,
  conf.level = 0.95
)

print(t_test_q1_1)

# Output:
# Paired t-test
# data:  post_wks_data$`1.1` and pre_wks_data$`1.1`
# t = _____, df = _____, p-value = _____
# alternative hypothesis: true difference in means is not equal to 0
# 95 percent confidence interval:
#  _____  _____
# sample estimates:
# mean of the differences
#               _____
```

**Extracted Results:**
- **t-statistic:** _____
- **df (degrees of freedom):** _____ (should be N - 1)
- **p-value:** _____ (exact value, e.g., 0.00234)
- **Mean difference:** _____ (Post - Pre)
- **95% CI of difference:** [_____, _____]

**Significance Determination:**
- p < 0.001: *** (highly significant)
- p < 0.01:  ** (very significant)
- p < 0.05:  * (significant)
- p ‚â• 0.05:  ns (not significant)

**This test:** _____ (fill in *, **, ***, or ns)

---

**Cohen's d Effect Size Calculation:**

**Formula:** d = (Mean_post - Mean_pre) / SD_pooled

**R Code:**
```r
library(effsize)
cohen.d(post_wks_data$`1.1`, pre_wks_data$`1.1`, paired=TRUE)

# OR manual calculation:
mean_diff <- mean(post_wks_data$`1.1` - pre_wks_data$`1.1`)
sd_diff <- sd(post_wks_data$`1.1` - pre_wks_data$`1.1`)
cohens_d <- mean_diff / sd_diff

# Output: d = _____
```

**Calculated Cohen's d:** _____

**Effect Size Interpretation:**
- |d| < 0.2: Negligible effect
- 0.2 ‚â§ |d| < 0.5: Small effect
- 0.5 ‚â§ |d| < 0.8: Medium effect
- |d| ‚â• 0.8: Large effect

**This effect:** _____ (Negligible / Small / Medium / Large)

---

**Manual Verification of t-statistic:**

```r
# Formula: t = mean_diff / (sd_diff / sqrt(n))
mean_diff <- _____
sd_diff <- _____
n <- _____

se_diff <- sd_diff / sqrt(n)
t_calculated <- mean_diff / se_diff

# Should match R output: _____
```

**Verification:**
- [ ] t-statistic matches R output (¬±0.01 tolerance)
- [ ] df = N - 1 = _____ ‚úì
- [ ] p-value makes sense (very small t ‚Üí large p, large t ‚Üí small p)
- [ ] Mean difference equals (Post mean - Pre mean)
- [ ] CI doesn't include 0 if p < 0.05
- [ ] Cohen's d calculated correctly

---

**Expected JSON:**
```json
{
  "question": "q1_1",
  "label": "Relevance to practice today",
  "n": _____,
  "meanDifference": _____,
  "sdDifference": _____,
  "tStatistic": _____,
  "df": _____,
  "pValue": _____,
  "ci95Difference": [_____, _____],
  "cohensD": _____,
  "effectSizeInterpretation": "Large",
  "significant": true,
  "significanceLevel": "***"
}
```

---

### Q1.2 ‚Äî Paired T-Test

**[Repeat entire structure for Q1.2]**

**R Output:**
```r
t.test(post_wks_data$`1.2`, pre_wks_data$`1.2`, paired=TRUE)
```

**Results:**
- **t:** _____
- **df:** _____
- **p-value:** _____
- **Mean difference:** _____
- **Cohen's d:** _____
- **Significance:** _____ (*, **, ***, ns)
- **Effect size:** _____ (Small/Medium/Large)

**Expected JSON:**
```json
{
  "question": "q1_2",
  "label": "Future relevance",
  "tStatistic": _____,
  "pValue": _____,
  "cohensD": _____,
  "significanceLevel": "___"
}
```

---

### Questions 2-12 (if paired)

**[For each question with pre AND post data, repeat t-test structure]**

**Note:** Questions 4-9 may not have pre-workshop data. If so, mark as "Not applicable - Post-only question."

---

## üéØ Aggregated Metrics

### Overall Workshop Effectiveness

#### Summary of Significant Changes

**R Code to Count Significant Results:**
```r
# Assuming p-values stored in vector
p_values <- c(p_q1_1, p_q1_2, p_q2, ..., p_q12)
effect_sizes <- c(d_q1_1, d_q1_2, d_q2, ..., d_q12)

# Count significant (p < 0.05)
n_significant <- sum(p_values < 0.05, na.rm=TRUE)
n_total <- length(p_values)

# Mean effect size
mean_effect <- mean(effect_sizes, na.rm=TRUE)
```

**Results:**
- **Total Questions Analyzed:** _____ (questions with pre AND post data)
- **Significant Improvements (p < 0.05):** _____ questions
- **Not Significant (p ‚â• 0.05):** _____ questions
- **Questions Declined (if any):** _____ questions
- **Mean Cohen's d:** _____ (across all questions)
- **Range of Effect Sizes:** [_____ to _____]

---

#### Detailed Results Table

| Question | Label (Short) | Pre Mean | Post Mean | Difference | p-value | Cohen's d | Sig Level |
|----------|---------------|----------|-----------|------------|---------|-----------|-----------|
| Q1.1     | Relevance today | _____  | _____     | _____      | _____   | _____     | ___       |
| Q1.2     | Future relevance | _____ | _____     | _____      | _____   | _____     | ___       |
| Q2       | [Label]       | _____    | _____     | _____      | _____   | _____     | ___       |
| Q3       | [Label]       | N/A      | N/A       | N/A        | N/A     | N/A       | N/A       |
| Q4       | [Label]       | N/A      | _____     | N/A        | N/A     | N/A       | N/A       |
| ...      | ...           | ...      | ...       | ...        | ...     | ...       | ...       |

**Key:**
- Sig Level: *** (p<0.001), ** (p<0.01), * (p<0.05), ns (p‚â•0.05)
- N/A: Not applicable (question not present in both surveys)

---

#### Largest Effect Sizes

**Top 3 Questions with Biggest Change:**

1. **Q___:** [Question label]
   - Cohen's d = _____
   - Mean change = _____ points
   - p-value = _____

2. **Q___:** [Question label]
   - Cohen's d = _____
   - Mean change = _____ points
   - p-value = _____

3. **Q___:** [Question label]
   - Cohen's d = _____
   - Mean change = _____ points
   - p-value = _____

---

#### Questions with No Significant Change

**List questions where p ‚â• 0.05:**

- **Q___:** [Label] - p = _____, d = _____
- **Q___:** [Label] - p = _____, d = _____
- **Q___:** [Label] - p = _____, d = _____

**Possible Reasons for Non-Significance:**
- Already high baseline (ceiling effect)
- Not addressed by workshop content
- Larger sample needed
- True lack of effect

---

**Expected JSON:**
```json
{
  "summary": {
    "totalQuestions": _____,
    "significantImprovements": _____,
    "noChange": _____,
    "declined": _____,
    "meanEffectSize": _____,
    "rangeEffectSizes": [_____, _____],
    "largestImprovement": {
      "question": "q___",
      "label": "[Question text]",
      "cohensD": _____,
      "pValue": _____
    },
    "topThreeImprovements": [
      {
        "question": "q___",
        "label": "[Label]",
        "cohensD": _____,
        "meanChange": _____
      },
      {
        "question": "q___",
        "label": "[Label]",
        "cohensD": _____,
        "meanChange": _____
      },
      {
        "question": "q___",
        "label": "[Label]",
        "cohensD": _____,
        "meanChange": _____
      }
    ]
  }
}
```

---

## üíª R to JSON Export Scripts

### Complete Export Workflow

**1. Demographics JSON**

```r
library(jsonlite)

# Calculate demographics
n_paired <- nrow(pre_wks_data)  # Should match post
n_pre_total <- nrow(common_pre_wks_data)  # All pre respondents
n_post_total <- nrow(common_post_wks_data)  # All post respondents

demographics <- list(
  totalParticipants = n_paired,
  participantTypes = list(
    list(type = "Dermatologists", count = n_paired, percentage = 100)
  ),
  responseRate = list(
    preWorkshop = n_pre_total,
    postWorkshop = n_post_total,
    paired = n_paired,
    pairRate = round((n_paired / n_pre_total) * 100, 1)
  )
)

# Export
write(
  toJSON(demographics, pretty = TRUE, auto_unbox = TRUE),
  "public/data/melanoma-workshop/demographics.json"
)
```

---

**2. Baseline Attitudes JSON (Q1.1, Q1.2)**

```r
# Q1.1 Pre
q1_1_pre <- describe(pre_wks_data$`1.1`)
q1_1_pre_freq <- table(pre_wks_data$`1.1`)

q1_1_pre_mean <- q1_1_pre$mean
q1_1_pre_sd <- q1_1_pre$sd
q1_1_pre_n <- q1_1_pre$n

# Calculate CI
q1_1_pre_se <- q1_1_pre_sd / sqrt(q1_1_pre_n)
q1_1_pre_ci <- c(
  q1_1_pre_mean - 1.96 * q1_1_pre_se,
  q1_1_pre_mean + 1.96 * q1_1_pre_se
)

# Q1.2 Pre (same process)
q1_2_pre <- describe(pre_wks_data$`1.2`)
q1_2_pre_freq <- table(pre_wks_data$`1.2`)

q1_2_pre_mean <- q1_2_pre$mean
q1_2_pre_sd <- q1_2_pre$sd
q1_2_pre_n <- q1_2_pre$n

q1_2_pre_se <- q1_2_pre_sd / sqrt(q1_2_pre_n)
q1_2_pre_ci <- c(
  q1_2_pre_mean - 1.96 * q1_2_pre_se,
  q1_2_pre_mean + 1.96 * q1_2_pre_se
)

# Build JSON structure
baseline_attitudes <- list(
  q1_1 = list(
    label = "Melanoma genomic testing is relevant to my practice today",
    category = "Attitudes - Current Relevance",
    preWorkshop = list(
      mean = round(q1_1_pre_mean, 2),
      sd = round(q1_1_pre_sd, 2),
      n = q1_1_pre_n,
      median = median(pre_wks_data$`1.1`, na.rm=TRUE),
      ci95 = round(q1_1_pre_ci, 2),
      responses = as.list(q1_1_pre_freq)
    )
  ),
  q1_2 = list(
    label = "Melanoma genomic testing will become increasingly relevant in the future",
    category = "Attitudes - Future Relevance",
    preWorkshop = list(
      mean = round(q1_2_pre_mean, 2),
      sd = round(q1_2_pre_sd, 2),
      n = q1_2_pre_n,
      median = median(pre_wks_data$`1.2`, na.rm=TRUE),
      ci95 = round(q1_2_pre_ci, 2),
      responses = as.list(q1_2_pre_freq)
    )
  )
)

# Export
write(
  toJSON(baseline_attitudes, pretty = TRUE, auto_unbox = TRUE),
  "public/data/melanoma-workshop/baseline_attitudes.json"
)
```

---

**3. Knowledge Change JSON (All Questions)**

```r
# Function to create question comparison
create_comparison <- function(question_id, label, category, pre_data, post_data) {

  # Pre stats
  pre_desc <- describe(pre_data)
  pre_mean <- pre_desc$mean
  pre_sd <- pre_desc$sd
  pre_n <- pre_desc$n
  pre_se <- pre_sd / sqrt(pre_n)
  pre_ci <- c(pre_mean - 1.96 * pre_se, pre_mean + 1.96 * pre_se)

  # Post stats
  post_desc <- describe(post_data)
  post_mean <- post_desc$mean
  post_sd <- post_desc$sd
  post_n <- post_desc$n
  post_se <- post_sd / sqrt(post_n)
  post_ci <- c(post_mean - 1.96 * post_se, post_mean + 1.96 * post_se)

  # Change
  mean_diff <- post_mean - pre_mean
  pct_change <- (mean_diff / pre_mean) * 100

  # Build list
  list(
    id = question_id,
    label = label,
    category = category,
    preWorkshop = list(
      mean = round(pre_mean, 2),
      sd = round(pre_sd, 2),
      ci95 = round(pre_ci, 2)
    ),
    postWorkshop = list(
      mean = round(post_mean, 2),
      sd = round(post_sd, 2),
      ci95 = round(post_ci, 2)
    ),
    change = list(
      meanDifference = round(mean_diff, 2),
      percentChange = round(pct_change, 1)
    )
  )
}

# Create list for each question
questions <- list(
  create_comparison(
    "q1_1",
    "Relevant to practice today",
    "Attitudes",
    pre_wks_data$`1.1`,
    post_wks_data$`1.1`
  ),
  create_comparison(
    "q1_2",
    "Future relevance",
    "Attitudes",
    pre_wks_data$`1.2`,
    post_wks_data$`1.2`
  )
  # Add more questions...
)

# Calculate summary
all_effect_sizes <- c(...)  # Fill from statistical tests
summary_stats <- list(
  totalQuestions = length(questions),
  significantImprovements = sum(...),  # Count from t-tests
  noChange = ...,
  declined = 0,
  meanEffectSize = round(mean(all_effect_sizes), 2)
)

# Combine
knowledge_change <- list(
  questions = questions,
  summary = summary_stats
)

# Export
write(
  toJSON(knowledge_change, pretty = TRUE, auto_unbox = TRUE),
  "public/data/melanoma-workshop/knowledge_change.json"
)
```

---

**4. Statistical Tests JSON**

```r
# Function to create t-test result
create_ttest_result <- function(question_id, label, pre_data, post_data) {

  # Paired t-test
  t_result <- t.test(post_data, pre_data, paired = TRUE)

  # Effect size
  library(effsize)
  d_result <- cohen.d(post_data, pre_data, paired = TRUE)

  # Significance level
  p <- t_result$p.value
  sig_level <- if(p < 0.001) "***" else if(p < 0.01) "**" else if(p < 0.05) "*" else "ns"

  # Effect interpretation
  d <- d_result$estimate
  effect_interp <- if(abs(d) >= 0.8) "Large" else if(abs(d) >= 0.5) "Medium" else if(abs(d) >= 0.2) "Small" else "Negligible"

  # Build result
  list(
    question = question_id,
    label = label,
    n = length(pre_data),
    meanDifference = round(t_result$estimate, 2),
    sdDifference = round(sd(post_data - pre_data), 2),
    tStatistic = round(t_result$statistic, 2),
    df = t_result$parameter,
    pValue = round(p, 5),
    ci95Difference = round(t_result$conf.int, 2),
    cohensD = round(d, 2),
    effectSizeInterpretation = effect_interp,
    significant = p < 0.05,
    significanceLevel = sig_level
  )
}

# Create test results
paired_ttests <- list(
  create_ttest_result("q1_1", "Relevance today",
                      pre_wks_data$`1.1`, post_wks_data$`1.1`),
  create_ttest_result("q1_2", "Future relevance",
                      pre_wks_data$`1.2`, post_wks_data$`1.2`)
  # Add more...
)

# Overall analysis
all_d <- sapply(paired_ttests, function(x) x$cohensD)
all_p <- sapply(paired_ttests, function(x) x$pValue)

overall <- list(
  averageEffectSize = round(mean(all_d), 2),
  rangeEffectSizes = round(range(all_d), 2),
  questionsSignificant = sum(all_p < 0.05),
  questionsNotSignificant = sum(all_p >= 0.05)
)

# Combine
statistical_tests <- list(
  pairedTTests = paired_ttests,
  overallAnalysis = overall
)

# Export
write(
  toJSON(statistical_tests, pretty = TRUE, auto_unbox = TRUE),
  "public/data/melanoma-workshop/statistical_tests.json"
)
```

---

**5. Master Export Script**

**Save this as: `export_all_json.R`**

```r
# Melanoma Workshop - Export All JSON Files
# Run this script after all analyses are complete

library(jsonlite)
library(psych)
library(effsize)

# Load cleaned data
pre_wks_data <- read.csv("path/to/Paired-Pre-WKS-Clean.csv")
post_wks_data <- read.csv("path/to/Paired-Post-WKS-Clean.csv")

# Create output directory
dir.create("public/data/melanoma-workshop", recursive = TRUE, showWarnings = FALSE)

# 1. Demographics
# [Copy code from above]

# 2. Baseline Attitudes
# [Copy code from above]

# 3. Knowledge Change
# [Copy code from above]

# 4. Statistical Tests
# [Copy code from above]

cat("‚úì All JSON files exported successfully!\n")
cat("Files created:\n")
cat("  - demographics.json\n")
cat("  - baseline_attitudes.json\n")
cat("  - knowledge_change.json\n")
cat("  - statistical_tests.json\n")
```

---

## ‚úÖ Final Verification Checklist

### Data Integrity

- [ ] **Paired participant count consistent:** Same N in pre and post datasets
- [ ] **No data entry errors:** Cross-check random sample with raw Excel file
- [ ] **Scale transformations verified:** Q1.1 and Q1.2 correctly reversed
- [ ] **Missing values handled:** All "N/A" converted to proper NA
- [ ] **Numeric conversion successful:** All Likert responses are numeric type

---

### Calculation Accuracy

#### For Each Question:
- [ ] **Pre-workshop mean** matches R `describe()` output (¬±0.01)
- [ ] **Post-workshop mean** matches R output (¬±0.01)
- [ ] **Standard deviations** match R output (¬±0.01)
- [ ] **95% CIs calculated correctly:** mean ¬± 1.96*(sd/‚àön)
- [ ] **Frequency distributions sum to N**

#### For Each Paired T-Test:
- [ ] **t-statistic** matches R `t.test()` output (¬±0.01)
- [ ] **p-value** matches R output (¬±0.0001)
- [ ] **df** equals N - 1
- [ ] **Mean difference** equals Post mean - Pre mean
- [ ] **CI of difference** matches R output
- [ ] **Cohen's d** calculated correctly: mean_diff / sd_diff
- [ ] **Significance level assigned correctly** (*, **, ***, ns)

#### Aggregated Metrics:
- [ ] **Count of significant questions** matches manual count (p < 0.05)
- [ ] **Mean effect size** equals average of all Cohen's d values
- [ ] **Largest improvement** correctly identified (highest Cohen's d)

---

### JSON File Validation

- [ ] **demographics.json** parses without errors (use jsonlint.com)
- [ ] **baseline_attitudes.json** parses correctly
- [ ] **knowledge_change.json** parses correctly
- [ ] **statistical_tests.json** parses correctly
- [ ] **All numeric values** formatted consistently (2 decimal places for means/SDs)
- [ ] **All arrays/objects** have proper brackets and commas
- [ ] **No trailing commas** in JSON files

---

### Cross-Reference with Manuscript

- [ ] **Sample size (N)** matches Final Manuscript.pdf
- [ ] **Key statistics** match poster and manuscript results
- [ ] **Significant findings** align with published conclusions
- [ ] **Effect sizes** consistent with reported values
- [ ] **Question wording** exactly matches survey instrument

---

### Web Visualization Verification

*(To be completed after implementing web report)*

- [ ] **Charts display correct data** (visual spot-check)
- [ ] **Tooltips show accurate values** (hover to verify)
- [ ] **Statistical significance indicators correct** (*, **, ***)
- [ ] **Error bars represent 95% CIs** properly
- [ ] **Pre/Post color coding consistent** (Blue = Pre, Green = Post)
- [ ] **No console errors** when loading data
- [ ] **All sections render** without missing data

---

## üìù Notes & Decisions Log

### Decision 1: Paired vs Common Data
**Date:** [To be filled]
**Decision:** Use PAIRED datasets (n = 25) for all pre/post comparisons
**Rationale:** Paired t-tests require matched observations; using common (all participants) would violate this assumption
**Impact:** Higher statistical power, more valid inference

---

### Decision 2: Question Exclusions
**Date:** [To be filled]
**Questions Excluded:** [List any questions not analyzed]
**Reason:** [Pre-only, Post-only, too many missing values, etc.]
**Impact:** [Reduced total question count to X]

---

### Decision 3: Missing Data Handling
**Date:** [To be filled]
**Approach:** Listwise deletion (exclude participants with missing data on specific question)
**Alternative Considered:** Multiple imputation
**Rationale:** Low missingness rate, paired design requires complete cases anyway
**Impact:** N varies slightly by question (document in each analysis)

---

### Unexpected Finding 1:
**Date:** [To be filled]
**Finding:** [Description of any unexpected results]
**Verification:** [How you confirmed it's correct, not an error]
**Explanation:** [Possible reasons for unexpected finding]

---

## üéì Lessons Learned

### What Went Well:
- [To be filled after data extraction]

### Challenges Faced:
- [To be filled during process]

### Time Savers for Next Project:
- [Document any shortcuts or efficient workflows discovered]

### Would Do Differently:
- [Reflections on process improvements]

---

**Document Status:** ‚úì Template Complete ‚Äî Ready for Data Entry

**Next Steps:**
1. Run all R markdown files to generate current results
2. Fill in all "\_\_\_\_\_" blanks with actual values
3. Complete verification checklists as you go
4. Export JSON files using provided scripts
5. Update development log with reference to this document

**Estimated Time to Complete:** 3-4 hours (careful verification)

---

*Last Updated: 2025-10-10*
*Created by: Claude Code*
*Reference: MelanomaWorkshop-DEVELOPMENT_LOG.md*
